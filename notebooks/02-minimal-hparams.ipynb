{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3822aac4-d5eb-4979-b237-70c80d2489e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0297c907",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pylab as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import swyft.lightning as sl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "370c159f-de20-4a20-8c9d-72902c3e05fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Simulator(sl.Simulator):\n",
    "    def __init__(self, bounds = None):\n",
    "        super().__init__()\n",
    "        self.on_after_forward = sl.to_numpy32\n",
    "        \n",
    "    def forward(self, trace):\n",
    "        z = trace.sample('z', np.random.rand, 3)\n",
    "        x = trace.sample('x', lambda z: z + np.random.randn(3)*0.02, z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3e6dc7e9-ff0a-479d-a4e8-fd8025717327",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(sl.SwyftModule):\n",
    "    def __init__(self, dropout = 0.1, lr = 1e-4):\n",
    "        super().__init__()\n",
    "        self.classifier = sl.RatioEstimatorMLP1d(3, 3, hidden_features = 256, dropout = self.hparams.dropout)\n",
    "        \n",
    "    def forward(self, x, z):\n",
    "        x = x['x']\n",
    "        z = z['z']\n",
    "        ratios_z = self.classifier(x, z)\n",
    "        return dict(z = ratios_z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ae869371-5e0c-4433-a183-776ae7d8fb1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:00<00:00, 31347.56it/s]\n"
     ]
    }
   ],
   "source": [
    "simulator = Simulator()\n",
    "samples = simulator.sample(1000).to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f77353b8-042b-4408-bab3-84f7e59def92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deprecation warning: Use dataloaders directly rathe than this data module for transparency.\n"
     ]
    }
   ],
   "source": [
    "datamodule = sl.SwyftDataModule(store = samples, batch_size = 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "41f7765b-45b8-4684-b820-4f75c9719857",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name       | Type                | Params\n",
      "---------------------------------------------------\n",
      "0 | classifier | RatioEstimatorMLP1d | 800 K \n",
      "---------------------------------------------------\n",
      "800 K     Trainable params\n",
      "0         Non-trainable params\n",
      "800 K     Total params\n",
      "3.201     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation sanity check:   0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/weniger/miniconda3b/envs/zero/lib/python3.9/site-packages/pytorch_lightning/trainer/data_loading.py:132: UserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 24 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                      "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/weniger/miniconda3b/envs/zero/lib/python3.9/site-packages/pytorch_lightning/trainer/data_loading.py:132: UserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 24 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "/home/weniger/miniconda3b/envs/zero/lib/python3.9/site-packages/pytorch_lightning/trainer/data_loading.py:432: UserWarning: The number of training samples (7) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:  78%|███████▊  | 7/9 [00:00<00:00, 64.15it/s, loss=247, v_num=8] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 0: 100%|██████████| 9/9 [00:00<00:00, 69.70it/s, loss=247, v_num=8, val_loss=1.12e+3]\n",
      "Epoch 1:  78%|███████▊  | 7/9 [00:00<00:00, 74.74it/s, loss=149, v_num=8, val_loss=1.12e+3]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 1: 100%|██████████| 9/9 [00:00<00:00, 79.91it/s, loss=149, v_num=8, val_loss=62.60]  \n",
      "Epoch 2:  78%|███████▊  | 7/9 [00:00<00:00, 74.24it/s, loss=108, v_num=8, val_loss=62.60]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 2: 100%|██████████| 9/9 [00:00<00:00, 80.83it/s, loss=108, v_num=8, val_loss=10.10]\n",
      "Epoch 3:  78%|███████▊  | 7/9 [00:00<00:00, 70.26it/s, loss=17.4, v_num=8, val_loss=10.10]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 3: 100%|██████████| 9/9 [00:00<00:00, 77.52it/s, loss=17.4, v_num=8, val_loss=4.590]\n",
      "Epoch 4:  78%|███████▊  | 7/9 [00:00<00:00, 75.52it/s, loss=5.6, v_num=8, val_loss=4.590] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 4: 100%|██████████| 9/9 [00:00<00:00, 81.82it/s, loss=5.6, v_num=8, val_loss=3.720]\n",
      "Epoch 5:  78%|███████▊  | 7/9 [00:00<00:00, 68.78it/s, loss=3.55, v_num=8, val_loss=3.720]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 5: 100%|██████████| 9/9 [00:00<00:00, 76.20it/s, loss=3.55, v_num=8, val_loss=2.890]\n",
      "Epoch 6:  78%|███████▊  | 7/9 [00:00<00:00, 73.30it/s, loss=2.97, v_num=8, val_loss=2.890]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 6: 100%|██████████| 9/9 [00:00<00:00, 79.53it/s, loss=2.97, v_num=8, val_loss=2.430]\n",
      "Epoch 7:  78%|███████▊  | 7/9 [00:00<00:00, 72.64it/s, loss=2.5, v_num=8, val_loss=2.430] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 7: 100%|██████████| 9/9 [00:00<00:00, 73.53it/s, loss=2.5, v_num=8, val_loss=2.510]\n",
      "Epoch 8:  78%|███████▊  | 7/9 [00:00<00:00, 79.31it/s, loss=2.16, v_num=8, val_loss=2.510]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 8: 100%|██████████| 9/9 [00:00<00:00, 84.90it/s, loss=2.16, v_num=8, val_loss=2.050]\n",
      "Epoch 9:  78%|███████▊  | 7/9 [00:00<00:00, 67.85it/s, loss=1.88, v_num=8, val_loss=2.050]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 9: 100%|██████████| 9/9 [00:00<00:00, 75.67it/s, loss=1.88, v_num=8, val_loss=2.240]\n",
      "Epoch 10:  78%|███████▊  | 7/9 [00:00<00:00, 77.33it/s, loss=1.69, v_num=8, val_loss=2.240]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 10: 100%|██████████| 9/9 [00:00<00:00, 78.80it/s, loss=1.69, v_num=8, val_loss=1.670]\n",
      "Epoch 11:  78%|███████▊  | 7/9 [00:00<00:00, 73.67it/s, loss=1.56, v_num=8, val_loss=1.670]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 11: 100%|██████████| 9/9 [00:00<00:00, 74.59it/s, loss=1.56, v_num=8, val_loss=1.600]\n",
      "Epoch 12:  78%|███████▊  | 7/9 [00:00<00:00, 67.73it/s, loss=1.47, v_num=8, val_loss=1.600]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 12: 100%|██████████| 9/9 [00:00<00:00, 75.05it/s, loss=1.47, v_num=8, val_loss=1.560]\n",
      "Epoch 13:  78%|███████▊  | 7/9 [00:00<00:00, 75.18it/s, loss=1.38, v_num=8, val_loss=1.560]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 13: 100%|██████████| 9/9 [00:00<00:00, 75.01it/s, loss=1.38, v_num=8, val_loss=1.440]\n",
      "Epoch 14:  78%|███████▊  | 7/9 [00:00<00:00, 77.29it/s, loss=1.32, v_num=8, val_loss=1.440]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 14: 100%|██████████| 9/9 [00:00<00:00, 83.86it/s, loss=1.32, v_num=8, val_loss=1.550]\n",
      "Epoch 15:  78%|███████▊  | 7/9 [00:00<00:00, 82.28it/s, loss=1.3, v_num=8, val_loss=1.550] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 15: 100%|██████████| 9/9 [00:00<00:00, 89.09it/s, loss=1.3, v_num=8, val_loss=1.580]\n",
      "Epoch 16:  78%|███████▊  | 7/9 [00:00<00:00, 77.73it/s, loss=1.33, v_num=8, val_loss=1.580]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 16: 100%|██████████| 9/9 [00:00<00:00, 86.11it/s, loss=1.33, v_num=8, val_loss=1.420]\n",
      "Epoch 17:  78%|███████▊  | 7/9 [00:00<00:00, 72.84it/s, loss=1.31, v_num=8, val_loss=1.420]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 17: 100%|██████████| 9/9 [00:00<00:00, 79.05it/s, loss=1.31, v_num=8, val_loss=1.400]\n",
      "Epoch 18:  78%|███████▊  | 7/9 [00:00<00:00, 73.20it/s, loss=1.26, v_num=8, val_loss=1.400]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 18: 100%|██████████| 9/9 [00:00<00:00, 80.12it/s, loss=1.26, v_num=8, val_loss=1.360]\n",
      "Epoch 19:  78%|███████▊  | 7/9 [00:00<00:00, 76.70it/s, loss=1.21, v_num=8, val_loss=1.360]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 19: 100%|██████████| 9/9 [00:00<00:00, 78.31it/s, loss=1.21, v_num=8, val_loss=1.420]\n",
      "Epoch 20:  78%|███████▊  | 7/9 [00:00<00:00, 68.35it/s, loss=1.2, v_num=8, val_loss=1.420] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 20: 100%|██████████| 9/9 [00:00<00:00, 71.95it/s, loss=1.2, v_num=8, val_loss=1.370]\n",
      "Epoch 21:  78%|███████▊  | 7/9 [00:00<00:00, 72.20it/s, loss=1.21, v_num=8, val_loss=1.370]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 21: 100%|██████████| 9/9 [00:00<00:00, 78.58it/s, loss=1.21, v_num=8, val_loss=1.510]\n",
      "Epoch 21: 100%|██████████| 9/9 [00:00<00:00, 75.05it/s, loss=1.21, v_num=8, val_loss=1.510]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Restoring states from the checkpoint path at ./lightning_logs2/01-minimal-hparams/version_8/checkpoints/epoch=18-step=132.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loaded model weights from checkpoint at ./lightning_logs2/01-minimal-hparams/version_8/checkpoints/epoch=18-step=132.ckpt\n",
      "/home/weniger/miniconda3b/envs/zero/lib/python3.9/site-packages/pytorch_lightning/trainer/data_loading.py:132: UserWarning: The dataloader, test_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 24 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing: 0it [00:00, ?it/s]--------------------------------------------------------------------------------\n",
      "DATALOADER:0 TEST RESULTS\n",
      "{'hp/JS-div': 1.2884330749511719, 'hp/KL-div': -6.22100305557251}\n",
      "--------------------------------------------------------------------------------\n",
      "Testing: 100%|██████████| 8/8 [00:00<00:00, 129.09it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "/home/weniger/miniconda3b/envs/zero/lib/python3.9/site-packages/pytorch_lightning/core/datamodule.py:469: LightningDeprecationWarning: DataModule.setup has already been called, so it will not be called again. In v1.6 this behavior will change to always call DataModule.setup.\n",
      "  rank_zero_deprecation(\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name       | Type                | Params\n",
      "---------------------------------------------------\n",
      "0 | classifier | RatioEstimatorMLP1d | 800 K \n",
      "---------------------------------------------------\n",
      "800 K     Trainable params\n",
      "0         Non-trainable params\n",
      "800 K     Total params\n",
      "3.201     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:  78%|███████▊  | 7/9 [00:00<00:00, 80.74it/s, loss=6.54, v_num=9]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 0: 100%|██████████| 9/9 [00:00<00:00, 85.78it/s, loss=6.54, v_num=9, val_loss=3.950]\n",
      "Epoch 1:  78%|███████▊  | 7/9 [00:00<00:00, 68.80it/s, loss=4.71, v_num=9, val_loss=3.950]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 1: 100%|██████████| 9/9 [00:00<00:00, 76.26it/s, loss=4.71, v_num=9, val_loss=3.630]\n",
      "Epoch 2:  89%|████████▉ | 8/9 [00:00<00:00, 78.29it/s, loss=3.74, v_num=9, val_loss=3.630]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 2: 100%|██████████| 9/9 [00:00<00:00, 72.23it/s, loss=3.74, v_num=9, val_loss=2.960]\n",
      "Epoch 3:  78%|███████▊  | 7/9 [00:00<00:00, 73.77it/s, loss=2.03, v_num=9, val_loss=2.960]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 3: 100%|██████████| 9/9 [00:00<00:00, 81.28it/s, loss=2.03, v_num=9, val_loss=2.720]\n",
      "Epoch 4:  78%|███████▊  | 7/9 [00:00<00:00, 74.69it/s, loss=1.54, v_num=9, val_loss=2.720]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 4: 100%|██████████| 9/9 [00:00<00:00, 80.73it/s, loss=1.54, v_num=9, val_loss=2.480]\n",
      "Epoch 5:  78%|███████▊  | 7/9 [00:00<00:00, 76.18it/s, loss=1.34, v_num=9, val_loss=2.480]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 5: 100%|██████████| 9/9 [00:00<00:00, 83.17it/s, loss=1.34, v_num=9, val_loss=2.240]\n",
      "Epoch 6:  78%|███████▊  | 7/9 [00:00<00:00, 71.49it/s, loss=1.26, v_num=9, val_loss=2.240]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 6: 100%|██████████| 9/9 [00:00<00:00, 75.32it/s, loss=1.26, v_num=9, val_loss=2.280]\n",
      "Epoch 7:  78%|███████▊  | 7/9 [00:00<00:00, 78.39it/s, loss=1.22, v_num=9, val_loss=2.280]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 7: 100%|██████████| 9/9 [00:00<00:00, 84.39it/s, loss=1.22, v_num=9, val_loss=1.770]\n",
      "Epoch 8:  78%|███████▊  | 7/9 [00:00<00:00, 74.42it/s, loss=1.22, v_num=9, val_loss=1.770]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 8: 100%|██████████| 9/9 [00:00<00:00, 75.41it/s, loss=1.22, v_num=9, val_loss=1.790]\n",
      "Epoch 9:  78%|███████▊  | 7/9 [00:00<00:00, 74.84it/s, loss=1.21, v_num=9, val_loss=1.790]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 9: 100%|██████████| 9/9 [00:00<00:00, 81.67it/s, loss=1.21, v_num=9, val_loss=1.770]\n",
      "Epoch 10:  78%|███████▊  | 7/9 [00:00<00:00, 69.21it/s, loss=1.2, v_num=9, val_loss=1.770] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 10: 100%|██████████| 9/9 [00:00<00:00, 76.31it/s, loss=1.2, v_num=9, val_loss=1.460]\n",
      "Epoch 11:  78%|███████▊  | 7/9 [00:00<00:00, 70.89it/s, loss=1.16, v_num=9, val_loss=1.460]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 11: 100%|██████████| 9/9 [00:00<00:00, 77.91it/s, loss=1.16, v_num=9, val_loss=1.680]\n",
      "Epoch 12:  78%|███████▊  | 7/9 [00:00<00:00, 74.47it/s, loss=1.12, v_num=9, val_loss=1.680]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 12: 100%|██████████| 9/9 [00:00<00:00, 80.63it/s, loss=1.12, v_num=9, val_loss=1.380]\n",
      "Epoch 13:  78%|███████▊  | 7/9 [00:00<00:00, 70.63it/s, loss=1.09, v_num=9, val_loss=1.380]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 13: 100%|██████████| 9/9 [00:00<00:00, 76.28it/s, loss=1.09, v_num=9, val_loss=1.310]\n",
      "Epoch 14:  78%|███████▊  | 7/9 [00:00<00:00, 72.60it/s, loss=1.06, v_num=9, val_loss=1.310]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 14: 100%|██████████| 9/9 [00:00<00:00, 79.91it/s, loss=1.06, v_num=9, val_loss=1.310]\n",
      "Epoch 15:  78%|███████▊  | 7/9 [00:00<00:00, 78.89it/s, loss=1.06, v_num=9, val_loss=1.310]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 15: 100%|██████████| 9/9 [00:00<00:00, 80.19it/s, loss=1.06, v_num=9, val_loss=1.440]\n",
      "Epoch 16:  78%|███████▊  | 7/9 [00:00<00:00, 80.31it/s, loss=1.07, v_num=9, val_loss=1.440]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 16: 100%|██████████| 9/9 [00:00<00:00, 83.74it/s, loss=1.07, v_num=9, val_loss=1.350]\n",
      "Epoch 16: 100%|██████████| 9/9 [00:00<00:00, 80.70it/s, loss=1.07, v_num=9, val_loss=1.350]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/weniger/miniconda3b/envs/zero/lib/python3.9/site-packages/pytorch_lightning/core/datamodule.py:469: LightningDeprecationWarning: DataModule.teardown has already been called, so it will not be called again. In v1.6 this behavior will change to always call DataModule.teardown.\n",
      "  rank_zero_deprecation(\n",
      "Restoring states from the checkpoint path at ./lightning_logs2/01-minimal-hparams/version_9/checkpoints/epoch=13-step=97.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loaded model weights from checkpoint at ./lightning_logs2/01-minimal-hparams/version_9/checkpoints/epoch=13-step=97.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing: 0it [00:00, ?it/s]--------------------------------------------------------------------------------\n",
      "DATALOADER:0 TEST RESULTS\n",
      "{'hp/JS-div': 1.2166918516159058, 'hp/KL-div': -8.114272117614746}\n",
      "--------------------------------------------------------------------------------\n",
      "Testing: 100%|██████████| 8/8 [00:00<00:00, 135.49it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name       | Type                | Params\n",
      "---------------------------------------------------\n",
      "0 | classifier | RatioEstimatorMLP1d | 800 K \n",
      "---------------------------------------------------\n",
      "800 K     Trainable params\n",
      "0         Non-trainable params\n",
      "800 K     Total params\n",
      "3.201     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:  78%|███████▊  | 7/9 [00:00<00:00, 82.66it/s, loss=3.28, v_num=10]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 0: 100%|██████████| 9/9 [00:00<00:00, 89.19it/s, loss=3.28, v_num=10, val_loss=4.150]\n",
      "Epoch 1:  78%|███████▊  | 7/9 [00:00<00:00, 62.95it/s, loss=2.63, v_num=10, val_loss=4.150]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 1: 100%|██████████| 9/9 [00:00<00:00, 70.08it/s, loss=2.63, v_num=10, val_loss=4.170]\n",
      "Epoch 2:  78%|███████▊  | 7/9 [00:00<00:00, 78.46it/s, loss=2.12, v_num=10, val_loss=4.170]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 2: 100%|██████████| 9/9 [00:00<00:00, 85.01it/s, loss=2.12, v_num=10, val_loss=4.220]\n",
      "Epoch 3:  78%|███████▊  | 7/9 [00:00<00:00, 82.89it/s, loss=1.55, v_num=10, val_loss=4.220]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 3: 100%|██████████| 9/9 [00:00<00:00, 89.37it/s, loss=1.55, v_num=10, val_loss=3.250]\n",
      "Epoch 4:  78%|███████▊  | 7/9 [00:00<00:00, 75.97it/s, loss=1.36, v_num=10, val_loss=3.250]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 4: 100%|██████████| 9/9 [00:00<00:00, 76.33it/s, loss=1.36, v_num=10, val_loss=2.690]\n",
      "Epoch 5:  78%|███████▊  | 7/9 [00:00<00:00, 73.69it/s, loss=1.29, v_num=10, val_loss=2.690]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 5: 100%|██████████| 9/9 [00:00<00:00, 76.97it/s, loss=1.29, v_num=10, val_loss=2.030]\n",
      "Epoch 6:  78%|███████▊  | 7/9 [00:00<00:00, 73.59it/s, loss=1.23, v_num=10, val_loss=2.030]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 6: 100%|██████████| 9/9 [00:00<00:00, 79.76it/s, loss=1.23, v_num=10, val_loss=1.730]\n",
      "Epoch 7:  78%|███████▊  | 7/9 [00:00<00:00, 72.50it/s, loss=1.18, v_num=10, val_loss=1.730]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 7: 100%|██████████| 9/9 [00:00<00:00, 79.11it/s, loss=1.18, v_num=10, val_loss=1.530]\n",
      "Epoch 8:  78%|███████▊  | 7/9 [00:00<00:00, 71.97it/s, loss=1.14, v_num=10, val_loss=1.530]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 8: 100%|██████████| 9/9 [00:00<00:00, 74.80it/s, loss=1.14, v_num=10, val_loss=1.410]\n",
      "Epoch 9:  78%|███████▊  | 7/9 [00:00<00:00, 69.02it/s, loss=1.1, v_num=10, val_loss=1.410] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 9: 100%|██████████| 9/9 [00:00<00:00, 76.16it/s, loss=1.1, v_num=10, val_loss=1.360]\n",
      "Epoch 10:  78%|███████▊  | 7/9 [00:00<00:00, 73.22it/s, loss=1.07, v_num=10, val_loss=1.360]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 10: 100%|██████████| 9/9 [00:00<00:00, 79.61it/s, loss=1.07, v_num=10, val_loss=1.320]\n",
      "Epoch 11:  78%|███████▊  | 7/9 [00:00<00:00, 70.41it/s, loss=1.05, v_num=10, val_loss=1.320]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 11: 100%|██████████| 9/9 [00:00<00:00, 76.19it/s, loss=1.05, v_num=10, val_loss=1.390]\n",
      "Epoch 12:  78%|███████▊  | 7/9 [00:00<00:00, 80.32it/s, loss=1.04, v_num=10, val_loss=1.390]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 12: 100%|██████████| 9/9 [00:00<00:00, 85.99it/s, loss=1.04, v_num=10, val_loss=1.220]\n",
      "Epoch 13:  78%|███████▊  | 7/9 [00:00<00:00, 77.15it/s, loss=1.03, v_num=10, val_loss=1.220]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 13: 100%|██████████| 9/9 [00:00<00:00, 81.44it/s, loss=1.03, v_num=10, val_loss=1.320]\n",
      "Epoch 14:  78%|███████▊  | 7/9 [00:00<00:00, 79.72it/s, loss=1.03, v_num=10, val_loss=1.320]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 14: 100%|██████████| 9/9 [00:00<00:00, 85.60it/s, loss=1.03, v_num=10, val_loss=1.430]\n",
      "Epoch 15:  78%|███████▊  | 7/9 [00:00<00:00, 76.81it/s, loss=1.02, v_num=10, val_loss=1.430]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 15: 100%|██████████| 9/9 [00:00<00:00, 78.60it/s, loss=1.02, v_num=10, val_loss=1.330]\n",
      "Epoch 15: 100%|██████████| 9/9 [00:00<00:00, 74.86it/s, loss=1.02, v_num=10, val_loss=1.330]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Restoring states from the checkpoint path at ./lightning_logs2/01-minimal-hparams/version_10/checkpoints/epoch=12-step=90.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loaded model weights from checkpoint at ./lightning_logs2/01-minimal-hparams/version_10/checkpoints/epoch=12-step=90.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing: 0it [00:00, ?it/s]--------------------------------------------------------------------------------\n",
      "DATALOADER:0 TEST RESULTS\n",
      "{'hp/JS-div': 1.1405411958694458, 'hp/KL-div': -7.927431583404541}\n",
      "--------------------------------------------------------------------------------\n",
      "Testing: 100%|██████████| 8/8 [00:00<00:00, 135.54it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name       | Type                | Params\n",
      "---------------------------------------------------\n",
      "0 | classifier | RatioEstimatorMLP1d | 800 K \n",
      "---------------------------------------------------\n",
      "800 K     Trainable params\n",
      "0         Non-trainable params\n",
      "800 K     Total params\n",
      "3.201     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:  78%|███████▊  | 7/9 [00:00<00:00, 82.09it/s, loss=4.02, v_num=11]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 0: 100%|██████████| 9/9 [00:00<00:00, 88.12it/s, loss=4.02, v_num=11, val_loss=4.160]\n",
      "Epoch 1:  89%|████████▉ | 8/9 [00:00<00:00, 79.87it/s, loss=3.63, v_num=11, val_loss=4.160]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 1: 100%|██████████| 9/9 [00:00<00:00, 77.76it/s, loss=3.63, v_num=11, val_loss=4.160]\n",
      "Epoch 2:  78%|███████▊  | 7/9 [00:00<00:00, 78.13it/s, loss=3.21, v_num=11, val_loss=4.160]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 2: 100%|██████████| 9/9 [00:00<00:00, 84.08it/s, loss=3.21, v_num=11, val_loss=4.140]\n",
      "Epoch 3:  78%|███████▊  | 7/9 [00:00<00:00, 69.31it/s, loss=2.52, v_num=11, val_loss=4.140]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 3: 100%|██████████| 9/9 [00:00<00:00, 76.00it/s, loss=2.52, v_num=11, val_loss=4.090]\n",
      "Epoch 4:  78%|███████▊  | 7/9 [00:00<00:00, 68.61it/s, loss=1.98, v_num=11, val_loss=4.090]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 4: 100%|██████████| 9/9 [00:00<00:00, 75.82it/s, loss=1.98, v_num=11, val_loss=3.890]\n",
      "Epoch 5:  78%|███████▊  | 7/9 [00:00<00:00, 70.14it/s, loss=1.61, v_num=11, val_loss=3.890]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 5: 100%|██████████| 9/9 [00:00<00:00, 76.72it/s, loss=1.61, v_num=11, val_loss=3.340]\n",
      "Epoch 6:  78%|███████▊  | 7/9 [00:00<00:00, 76.84it/s, loss=1.38, v_num=11, val_loss=3.340]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 6: 100%|██████████| 9/9 [00:00<00:00, 83.84it/s, loss=1.38, v_num=11, val_loss=2.540]\n",
      "Epoch 7:  78%|███████▊  | 7/9 [00:00<00:00, 66.49it/s, loss=1.26, v_num=11, val_loss=2.540]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 7: 100%|██████████| 9/9 [00:00<00:00, 68.99it/s, loss=1.26, v_num=11, val_loss=1.930]\n",
      "Epoch 8:  78%|███████▊  | 7/9 [00:00<00:00, 70.82it/s, loss=1.18, v_num=11, val_loss=1.930]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 8: 100%|██████████| 9/9 [00:00<00:00, 78.25it/s, loss=1.18, v_num=11, val_loss=1.590]\n",
      "Epoch 9:  78%|███████▊  | 7/9 [00:00<00:00, 64.64it/s, loss=1.13, v_num=11, val_loss=1.590]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 9: 100%|██████████| 9/9 [00:00<00:00, 71.74it/s, loss=1.13, v_num=11, val_loss=1.450]\n",
      "Epoch 10:  78%|███████▊  | 7/9 [00:00<00:00, 77.62it/s, loss=1.09, v_num=11, val_loss=1.450]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 10: 100%|██████████| 9/9 [00:00<00:00, 83.72it/s, loss=1.09, v_num=11, val_loss=1.310]\n",
      "Epoch 11:  78%|███████▊  | 7/9 [00:00<00:00, 77.67it/s, loss=1.06, v_num=11, val_loss=1.310]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 11: 100%|██████████| 9/9 [00:00<00:00, 83.55it/s, loss=1.06, v_num=11, val_loss=1.400]\n",
      "Epoch 12:  78%|███████▊  | 7/9 [00:00<00:00, 83.12it/s, loss=1.04, v_num=11, val_loss=1.400]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 12: 100%|██████████| 9/9 [00:00<00:00, 90.86it/s, loss=1.04, v_num=11, val_loss=1.310]\n",
      "Epoch 13:  78%|███████▊  | 7/9 [00:00<00:00, 84.14it/s, loss=1.05, v_num=11, val_loss=1.310]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 13: 100%|██████████| 9/9 [00:00<00:00, 89.09it/s, loss=1.05, v_num=11, val_loss=1.340]\n",
      "Epoch 13: 100%|██████████| 9/9 [00:00<00:00, 84.08it/s, loss=1.05, v_num=11, val_loss=1.340]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Restoring states from the checkpoint path at ./lightning_logs2/01-minimal-hparams/version_11/checkpoints/epoch=10-step=76.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loaded model weights from checkpoint at ./lightning_logs2/01-minimal-hparams/version_11/checkpoints/epoch=10-step=76.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing:  88%|████████▊ | 7/8 [00:00<00:00, 64.67it/s]--------------------------------------------------------------------------------\n",
      "DATALOADER:0 TEST RESULTS\n",
      "{'hp/JS-div': 1.1909857988357544, 'hp/KL-div': -7.024380683898926}\n",
      "--------------------------------------------------------------------------------\n",
      "Testing: 100%|██████████| 8/8 [00:00<00:00, 61.59it/s]\n"
     ]
    }
   ],
   "source": [
    "for lr in [1e-1, 1e-2, 1e-3, 1e-4]:\n",
    "    network = Network(dropout = 0.2, lr = lr)\n",
    "    trainer = sl.SwyftTrainer(accelerator = 'gpu', gpus=1, max_epochs = 100, **sl.tensorboard_config(save_dir = './lightning_logs2', name = '01-minimal-hparams', version=None))\n",
    "    trainer.fit(network, datamodule)\n",
    "    trainer.test(network, datamodule, ckpt_path = 'best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a88496e-23f2-449e-bc81-86a62e3ec65d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
