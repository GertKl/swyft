{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3822aac4-d5eb-4979-b237-70c80d2489e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Makes it easier to debug\n",
    "%load_ext autoreload\n",
    "#%load_ext line_profiler\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0297c907",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pylab as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import typing as tp\n",
    "from torch.nn import functional as F\n",
    "\n",
    "import swyft\n",
    "from swyft.lightning.components_v1 import (\n",
    "    MeanStd, SimpleDataset, subsample_posterior,\n",
    "    get_1d_rect_bounds, append_randomized, valmap, SwyftModel, persist_to_file, \n",
    "    equalize_tensors, SwyftTrainer, SampleStore, dictstoremap, DictDataset, SwyftModule, SwyftDataModule, RatioSamples,\n",
    "    RatioSampleStore, file_cache\n",
    ")\n",
    "\n",
    "import lensing_model\n",
    "from pytorch_lightning import loggers as pl_loggers\n",
    "\n",
    "from swyft.lightning.components_v1 import RatioEstimatorGaussian1d as RatioEstimatorGaussian1d_v1\n",
    "from swyft.lightning.components import RatioEstimatorGaussian1d, RatioEstimatorMLP1d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5b048d19-d01d-4f3e-928f-86d0764fcdda",
   "metadata": {},
   "outputs": [],
   "source": [
    "WORKS = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93d83b8b-4b96-4f92-b71b-84ecba33cc68",
   "metadata": {},
   "source": [
    "## Problem-specific analysis components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "db2c3024-004e-4ad1-8e9a-93999f462752",
   "metadata": {},
   "outputs": [],
   "source": [
    "KNN = 3\n",
    "SIGMA = 0.02\n",
    "NPIX_SRC = NPIX_IMG = 100\n",
    "\n",
    "class Model(SwyftModel):\n",
    "    def slow(self, pars):\n",
    "        torch.cuda.set_device(0)\n",
    "        torch.set_default_tensor_type(torch.cuda.FloatTensor)    \n",
    "        x, y, phi, q, r_ein, slope = pars['z_lens']\n",
    "        slope = 2.0\n",
    "        src_image = pars['z_src'].cuda()\n",
    "        img, coords = lensing_model.image_generator(x, y, phi, q, r_ein, slope, src_image)\n",
    "        X, Y, Xsrc, Ysrc = coords\n",
    "        kNN_idx = lensing_model.get_kNN_idx(X/5, -Y/5, Xsrc, Ysrc, k = KNN)  # TODO: Need to sort out strange 1/5 and -1/5 factors\n",
    "        torch.set_default_tensor_type(torch.FloatTensor)\n",
    "        return SampleStore(mu = img.cpu(), kNN_idx = kNN_idx.cpu(), X = X.cpu(), Y = Y.cpu(), Xsrc = Xsrc.cpu(), Ysrc = Ysrc.cpu())\n",
    "    \n",
    "    def fast(self, d):\n",
    "        img = d['mu'] + torch.randn_like(d['mu'])*SIGMA\n",
    "        return SampleStore(img=img)\n",
    "    \n",
    "    def prior(self, N, bounds = None):\n",
    "        src_samples = self.prior_src(N, bounds = bounds)\n",
    "        lens_samples = self.prior_lens(N, bounds = bounds)\n",
    "        return SampleStore(**src_samples, **lens_samples)\n",
    "    \n",
    "    # Draw from source prior\n",
    "    def prior_src(self, N, bounds = None):\n",
    "        if bounds is None or 'z_src' not in bounds:\n",
    "            R = lensing_model.RandomSource()\n",
    "            z_src = torch.stack([R().cpu() for _ in range(N)])\n",
    "        else:\n",
    "            n = 3\n",
    "            l, h = bounds['z_src'].low, bounds['z_src'].high\n",
    "            R = lensing_model.RandomSource()\n",
    "            z_src = []\n",
    "            for _ in range(N):\n",
    "                rnd = sum([R().cpu()-R().cpu() for _ in range(n)])\n",
    "                rnd -= rnd.min()\n",
    "                rnd /= rnd.max()\n",
    "                z_src.append(l+rnd*h)\n",
    "            z_src = torch.stack(z_src)\n",
    "        return SampleStore(z_src=z_src)\n",
    "\n",
    "    def prior_lens(self, N, bounds = None):\n",
    "        if bounds is not None:\n",
    "            low = bounds['z_lens'].low\n",
    "            high = bounds['z_lens'].high\n",
    "        else:\n",
    "            low =  np.array([-0.2, -0.2, 0, 0.2, 1.0, 1.5])\n",
    "            high = np.array([0.2, 0.2, 1.5, 0.9, 2.0, 2.5])\n",
    "        draw = np.array([np.random.uniform(low=low, high=high) for _ in range(N)])\n",
    "        return SampleStore(z_lens = torch.tensor(draw).float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fb6e5ea0-e5a9-433e-bd10-1f6fa9155e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = Model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fe89a65c-22bf-4f02-995a-2e92ef0c41e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#s_targets = m.sample(10)\n",
    "#torch.save(s_targets, \"test_targets.pt\")\n",
    "s_targets = torch.load(\"test_targets.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e0afb416-08aa-4499-8914-2b321d905f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Works\n",
    "\n",
    "class LensNetwork(SwyftModule):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.online_z_score = swyft.networks.OnlineDictStandardizingLayer(dict(img = (NPIX_IMG, NPIX_IMG)))\n",
    "        self.CNN = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(1, 10, 3),\n",
    "            torch.nn.MaxPool2d(2),\n",
    "            torch.nn.Conv2d(10, 20, 3),\n",
    "            torch.nn.MaxPool2d(2),\n",
    "            torch.nn.Conv2d(20, 40, 3),\n",
    "            torch.nn.MaxPool2d(2),\n",
    "            torch.nn.Flatten(),\n",
    "            torch.nn.LazyLinear(128),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.LazyLinear(256),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(256, 16),\n",
    "        )\n",
    "        if WORKS:\n",
    "            self.ptrans = swyft.networks.ParameterTransform(\n",
    "                6, [(0,), (1,), (2,), (3,), (4,), (5,)], online_z_score=False\n",
    "            )\n",
    "            n_marginals, n_block_parameters = self.ptrans.marginal_block_shape\n",
    "            n_observation_features = 16\n",
    "            self.classifier = swyft.networks.MarginalClassifier(\n",
    "                n_marginals,\n",
    "                n_observation_features + n_block_parameters,\n",
    "                hidden_features=256,\n",
    "                dropout_probability = 0.1,\n",
    "                num_blocks=3,\n",
    "            )\n",
    "        else:\n",
    "            self.c = RatioEstimatorMLP1d(16, 6)\n",
    "        \n",
    "    def forward(self, x, z):\n",
    "        # Digesting x\n",
    "        x = dict(img = x['img'])\n",
    "        x = self.online_z_score(x)['img']\n",
    "        x = self.CNN(x.unsqueeze(1)).squeeze(1)\n",
    "        \n",
    "        if WORKS:        \n",
    "            # Digesting z\n",
    "            z = self.ptrans(z['z_lens'])\n",
    "\n",
    "            # Combine!\n",
    "            x, z = equalize_tensors(x, z)\n",
    "            ratios = self.classifier(x, z)\n",
    "            w = RatioSamples(z.squeeze(-1), ratios)\n",
    "            return dict(z_lens=w)\n",
    "        else:\n",
    "            out = self.c(x, z['z_lens'])\n",
    "            return dict(z_lens = out)\n",
    "\n",
    "class SourceNetwork(SwyftModule):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.l = torch.nn.Linear(10, 10)\n",
    "        if WORKS:\n",
    "            self.reg1d = RatioEstimatorGaussian1d_v1(momentum = 0.1)\n",
    "        else:\n",
    "            self.reg1d = RatioEstimatorGaussian1d(momentum = 0.1)\n",
    "        self.L = torch.nn.Linear(NPIX_SRC**2, NPIX_SRC**2)\n",
    "        \n",
    "    def get_img_rec(self, x):\n",
    "        x_img = x['img']\n",
    "        x_kNN_idx = x['kNN_idx']\n",
    "        x_src_rec = lensing_model.deproject_idx(x_img, x_kNN_idx)[:,:,:,:].mean(dim=1)\n",
    "        x_src_rec = self.L(x_src_rec.view(-1, NPIX_SRC*NPIX_SRC)).view(-1, NPIX_SRC, NPIX_SRC)*0 + x_src_rec\n",
    "        return x_src_rec\n",
    "    \n",
    "    def forward(self, x, z):\n",
    "        x_img_rec = self.get_img_rec(x)\n",
    "        z_src = z['z_src']\n",
    "        x_img_rec, z_src = equalize_tensors(x_img_rec, z_src)\n",
    "        if WORKS:\n",
    "            ratios = self.reg1d(x_img_rec, z_src)\n",
    "            w = RatioSamples(ratios[...,1], ratios[...,0])\n",
    "            return dict(z_src = w)\n",
    "        else:\n",
    "            w = self.reg1d(x_img_rec, z_src)\n",
    "            return dict(z_src = w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eb94e0a7-d80e-46d0-82fd-eeb6143b5b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ntrain1, R1, ME = 500, 1, 10\n",
    "TARGET = 3\n",
    "tag = 'V03'\n",
    "INFER_SOURCE = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4979837a-be5f-43ef-8a84-e4752a1c9228",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/weniger/miniconda3/envs/p38/lib/python3.8/site-packages/torch-1.9.0-py3.8-linux-x86_64.egg/torch/nn/modules/lazy.py:178: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "/home/weniger/miniconda3/envs/p38/lib/python3.8/site-packages/pytorch_lightning/utilities/model_summary.py:438: UserWarning: A layer with UninitializedParameter was found. Thus, the total number of parameters detected may be inaccurate.\n",
      "  warning_cache.warn(\n",
      "\n",
      "  | Name           | Type                         | Params\n",
      "----------------------------------------------------------------\n",
      "0 | online_z_score | OnlineDictStandardizingLayer | 0     \n",
      "1 | CNN            | Sequential                   | 13.3 K\n",
      "2 | c              | RatioEstimatorMLP1d          | 110 K \n",
      "----------------------------------------------------------------\n",
      "123 K     Trainable params\n",
      "0         Non-trainable params\n",
      "123 K     Total params\n",
      "0.494     Total estimated model params size (MB)\n",
      "/home/weniger/miniconda3/envs/p38/lib/python3.8/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:631: UserWarning: Checkpoint directory /home/weniger/codes/swyft_papergui/notebooks/GUI paper/lightning_logs/version_8767861/checkpoints exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/weniger/miniconda3/envs/p38/lib/python3.8/site-packages/pytorch_lightning/trainer/data_loading.py:132: UserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 24 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "/home/weniger/miniconda3/envs/p38/lib/python3.8/site-packages/torch-1.9.0-py3.8-linux-x86_64.egg/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n",
      "/home/weniger/miniconda3/envs/p38/lib/python3.8/site-packages/torch-1.9.0-py3.8-linux-x86_64.egg/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "/home/weniger/miniconda3/envs/p38/lib/python3.8/site-packages/pytorch_lightning/trainer/data_loading.py:132: UserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 24 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "/home/weniger/miniconda3/envs/p38/lib/python3.8/site-packages/pytorch_lightning/trainer/data_loading.py:432: UserWarning: The number of training samples (4) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af6f374d0c9b481f890aa7f769bfbf49",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "/home/weniger/miniconda3/envs/p38/lib/python3.8/site-packages/pytorch_lightning/trainer/data_loading.py:132: UserWarning: The dataloader, test_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 24 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9963d511d3b945fba251d9ccf5be2edb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:0 TEST RESULTS\n",
      "{'hp/JS-div': 7.863509654998779, 'hp/KL-div': -1.4944143295288086}\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'hp/JS-div': 7.863509654998779, 'hp/KL-div': -1.4944143295288086}]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bounds = None\n",
    "results = []\n",
    "s0 = s_targets[TARGET]\n",
    "\n",
    "#tbl = pl_loggers.TensorBoardLogger(\"lightning_logs\", name = 'lensing_%s'%tag)#, default_hp_metric=True)\n",
    "# s1: img, lens, src ~ p(img|lens, src)p(lens)p(src)\n",
    "s1 = file_cache(lambda: m.sample(Ntrain1, bounds = bounds), './a_train_data.pt')\n",
    "\n",
    "# r1: p(z_lens|img)/p(z_lens)\n",
    "r1 = LensNetwork()\n",
    "\n",
    "# d1: split img vs z_lens\n",
    "# TODO: Specify x_keys = ['img'], z_keys=['z_lens']\n",
    "d1 = SwyftDataModule(s1, model = m, batch_size = 128)\n",
    "\n",
    "# Train r1 with d1\n",
    "t1 = SwyftTrainer(accelerator = 'gpu', gpus=1, max_epochs = ME)\n",
    "t1.fit(r1, d1)\n",
    "t1.test(r1, d1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d1205b6-41ca-496a-bda6-6f0f5770b6b1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "p38",
   "language": "python",
   "name": "p38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
