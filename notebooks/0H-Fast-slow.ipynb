{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b4c7a3f1-ab43-432e-a64f-b7f1358a24da",
   "metadata": {},
   "source": [
    "# Resampling observational noise\n",
    "\n",
    "First we need some imports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8e9d04e5-d08e-46ab-a520-4547dedf0487",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0297c907",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import stats\n",
    "import pylab as plt\n",
    "import torch\n",
    "import torchist\n",
    "import swyft"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab99366b-0783-46f5-be2d-80cbbb85e163",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Training data\n",
    "\n",
    "Now we generate training data.  As simple example, we consider the model\n",
    "\n",
    "$$\n",
    "x = z + \\epsilon\n",
    "$$\n",
    "\n",
    "where the parameter $z \\sim \\mathcal{N}(\\mu = 0, \\sigma = 1)$ is standard normal distributed, and $\\epsilon \\sim \\mathcal{N}(\\mu = 0, \\sigma = 0.1)$ is a small noise contribution.  We are interested in the posterior of $z$ given a measurement of parameter $x$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c0439f14-d49f-4e52-8916-49a785daede5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Simulator(swyft.Simulator):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.transform_samples = swyft.to_numpy32\n",
    "\n",
    "    def forward(self, trace):\n",
    "        z = trace.sample('z', lambda: np.random.rand(1))\n",
    "        x = trace.sample('x', lambda z: z + np.random.randn(1)*0.1, z)\n",
    "        \n",
    "sim = Simulator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4a1ed06f-9bbe-460d-bda3-400a3eaee6f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:00<00:00, 32344.49it/s]\n"
     ]
    }
   ],
   "source": [
    "samples = sim.sample(500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "97cf962b-dfc3-4d90-b60b-3ce3332f5404",
   "metadata": {},
   "outputs": [],
   "source": [
    "resampler = sim.get_resampler(targets = [\"x\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3e6dc7e9-ff0a-479d-a4e8-fd8025717327",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(swyft.SwyftModule):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.logratios = swyft.LogRatioEstimator_1dim(num_features = 1, num_params = 1, varnames = 'z')\n",
    "\n",
    "    def forward(self, A, B):\n",
    "        logratios = self.logratios(A['x'], B['z'])\n",
    "        return logratios"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2554dbed-fc91-45d2-bfa7-418cdaad67b6",
   "metadata": {},
   "source": [
    "## Trainer\n",
    "\n",
    "Training is now done using the `SwyftTrainer` class, which extends `pytorch_lightning.Trainer` by methods like `infer` (see below)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5683ce37-a8d0-4ed7-94a6-512ccc7babcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "trainer = swyft.SwyftTrainer(accelerator = 'gpu', max_epochs = 20, precision = 32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "053eff99-5d2b-4419-bce7-d938831b623e",
   "metadata": {},
   "source": [
    "The `swyft.Samples` class provides convenience functions to generate data loaders for training and validation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b1b09c64-a0e4-4d69-a639-a5843efac80c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dl_train = samples[:-100].get_dataloader(batch_size = 16, shuffle = True, on_after_load_sample = resampler)\n",
    "dl_valid = samples[-100:].get_dataloader(batch_size = 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c5811d37-d10b-49e8-a8ed-1e6d43caefa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "network = Network()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "41f7765b-45b8-4684-b820-4f75c9719857",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/weniger/miniconda3b/envs/zero/lib/python3.9/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:616: UserWarning: Checkpoint directory /home/weniger/codes/swyft/notebooks/lightning_logs/version_10034687/checkpoints exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type                   | Params\n",
      "-----------------------------------------------------\n",
      "0 | logratios | LogRatioEstimator_1dim | 17.4 K\n",
      "-----------------------------------------------------\n",
      "17.4 K    Trainable params\n",
      "0         Non-trainable params\n",
      "17.4 K    Total params\n",
      "0.070     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/weniger/miniconda3b/envs/zero/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:219: PossibleUserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 24 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                           "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/weniger/miniconda3b/envs/zero/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:219: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 24 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "/home/weniger/miniconda3b/envs/zero/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py:1894: PossibleUserWarning: The number of training batches (25) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:  78%|███████▊  | 25/32 [00:00<00:00, 102.46it/s, loss=-0.509, v_num=1e+7]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 0:  81%|████████▏ | 26/32 [00:00<00:00, 100.01it/s, loss=-0.509, v_num=1e+7]\n",
      "Epoch 0:  84%|████████▍ | 27/32 [00:00<00:00, 101.65it/s, loss=-0.509, v_num=1e+7]\n",
      "Epoch 0:  88%|████████▊ | 28/32 [00:00<00:00, 103.65it/s, loss=-0.509, v_num=1e+7]\n",
      "Epoch 0:  91%|█████████ | 29/32 [00:00<00:00, 105.53it/s, loss=-0.509, v_num=1e+7]\n",
      "Epoch 0:  94%|█████████▍| 30/32 [00:00<00:00, 107.40it/s, loss=-0.509, v_num=1e+7]\n",
      "Epoch 0:  97%|█████████▋| 31/32 [00:00<00:00, 109.31it/s, loss=-0.509, v_num=1e+7]\n",
      "Epoch 0: 100%|██████████| 32/32 [00:00<00:00, 109.09it/s, loss=-0.509, v_num=1e+7, val_loss=-.0479]\n",
      "Epoch 1:  78%|███████▊  | 25/32 [00:00<00:00, 100.92it/s, loss=-0.555, v_num=1e+7, val_loss=-.0479]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1:  81%|████████▏ | 26/32 [00:00<00:00, 98.57it/s, loss=-0.555, v_num=1e+7, val_loss=-.0479] \n",
      "Epoch 1:  84%|████████▍ | 27/32 [00:00<00:00, 100.68it/s, loss=-0.555, v_num=1e+7, val_loss=-.0479]\n",
      "Epoch 1:  88%|████████▊ | 28/32 [00:00<00:00, 102.77it/s, loss=-0.555, v_num=1e+7, val_loss=-.0479]\n",
      "Epoch 1:  91%|█████████ | 29/32 [00:00<00:00, 104.85it/s, loss=-0.555, v_num=1e+7, val_loss=-.0479]\n",
      "Epoch 1:  94%|█████████▍| 30/32 [00:00<00:00, 106.86it/s, loss=-0.555, v_num=1e+7, val_loss=-.0479]\n",
      "Epoch 1:  97%|█████████▋| 31/32 [00:00<00:00, 108.86it/s, loss=-0.555, v_num=1e+7, val_loss=-.0479]\n",
      "Epoch 1: 100%|██████████| 32/32 [00:00<00:00, 110.22it/s, loss=-0.555, v_num=1e+7, val_loss=-.384] \n",
      "Epoch 2:  78%|███████▊  | 25/32 [00:00<00:00, 96.04it/s, loss=-0.604, v_num=1e+7, val_loss=-.384] \n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 2:  81%|████████▏ | 26/32 [00:00<00:00, 95.35it/s, loss=-0.604, v_num=1e+7, val_loss=-.384]\n",
      "Epoch 2:  84%|████████▍ | 27/32 [00:00<00:00, 97.26it/s, loss=-0.604, v_num=1e+7, val_loss=-.384]\n",
      "Epoch 2:  88%|████████▊ | 28/32 [00:00<00:00, 99.23it/s, loss=-0.604, v_num=1e+7, val_loss=-.384]\n",
      "Epoch 2:  91%|█████████ | 29/32 [00:00<00:00, 101.07it/s, loss=-0.604, v_num=1e+7, val_loss=-.384]\n",
      "Epoch 2:  94%|█████████▍| 30/32 [00:00<00:00, 102.28it/s, loss=-0.604, v_num=1e+7, val_loss=-.384]\n",
      "Epoch 2:  97%|█████████▋| 31/32 [00:00<00:00, 103.28it/s, loss=-0.604, v_num=1e+7, val_loss=-.384]\n",
      "Epoch 2: 100%|██████████| 32/32 [00:00<00:00, 103.19it/s, loss=-0.604, v_num=1e+7, val_loss=-.529]\n",
      "Epoch 3:  78%|███████▊  | 25/32 [00:00<00:00, 95.48it/s, loss=-0.544, v_num=1e+7, val_loss=-.529] \n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 3:  81%|████████▏ | 26/32 [00:00<00:00, 94.83it/s, loss=-0.544, v_num=1e+7, val_loss=-.529]\n",
      "Epoch 3:  84%|████████▍ | 27/32 [00:00<00:00, 96.74it/s, loss=-0.544, v_num=1e+7, val_loss=-.529]\n",
      "Epoch 3:  88%|████████▊ | 28/32 [00:00<00:00, 98.18it/s, loss=-0.544, v_num=1e+7, val_loss=-.529]\n",
      "Epoch 3:  91%|█████████ | 29/32 [00:00<00:00, 99.51it/s, loss=-0.544, v_num=1e+7, val_loss=-.529]\n",
      "Epoch 3:  94%|█████████▍| 30/32 [00:00<00:00, 100.83it/s, loss=-0.544, v_num=1e+7, val_loss=-.529]\n",
      "Epoch 3:  97%|█████████▋| 31/32 [00:00<00:00, 102.46it/s, loss=-0.544, v_num=1e+7, val_loss=-.529]\n",
      "Epoch 3: 100%|██████████| 32/32 [00:00<00:00, 103.58it/s, loss=-0.544, v_num=1e+7, val_loss=-.559]\n",
      "Epoch 4:  78%|███████▊  | 25/32 [00:00<00:00, 96.38it/s, loss=-0.57, v_num=1e+7, val_loss=-.559]  \n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 4:  81%|████████▏ | 26/32 [00:00<00:00, 95.21it/s, loss=-0.57, v_num=1e+7, val_loss=-.559]\n",
      "Epoch 4:  84%|████████▍ | 27/32 [00:00<00:00, 97.27it/s, loss=-0.57, v_num=1e+7, val_loss=-.559]\n",
      "Epoch 4:  88%|████████▊ | 28/32 [00:00<00:00, 99.36it/s, loss=-0.57, v_num=1e+7, val_loss=-.559]\n",
      "Epoch 4:  91%|█████████ | 29/32 [00:00<00:00, 101.44it/s, loss=-0.57, v_num=1e+7, val_loss=-.559]\n",
      "Epoch 4:  94%|█████████▍| 30/32 [00:00<00:00, 103.51it/s, loss=-0.57, v_num=1e+7, val_loss=-.559]\n",
      "Epoch 4:  97%|█████████▋| 31/32 [00:00<00:00, 105.54it/s, loss=-0.57, v_num=1e+7, val_loss=-.559]\n",
      "Epoch 4: 100%|██████████| 32/32 [00:00<00:00, 106.88it/s, loss=-0.57, v_num=1e+7, val_loss=-.556]\n",
      "Epoch 5:  78%|███████▊  | 25/32 [00:00<00:00, 97.14it/s, loss=-0.572, v_num=1e+7, val_loss=-.556]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 5:  81%|████████▏ | 26/32 [00:00<00:00, 95.72it/s, loss=-0.572, v_num=1e+7, val_loss=-.556]\n",
      "Epoch 5:  84%|████████▍ | 27/32 [00:00<00:00, 97.69it/s, loss=-0.572, v_num=1e+7, val_loss=-.556]\n",
      "Epoch 5:  88%|████████▊ | 28/32 [00:00<00:00, 99.62it/s, loss=-0.572, v_num=1e+7, val_loss=-.556]\n",
      "Epoch 5:  91%|█████████ | 29/32 [00:00<00:00, 101.45it/s, loss=-0.572, v_num=1e+7, val_loss=-.556]\n",
      "Epoch 5:  94%|█████████▍| 30/32 [00:00<00:00, 103.33it/s, loss=-0.572, v_num=1e+7, val_loss=-.556]\n",
      "Epoch 5:  97%|█████████▋| 31/32 [00:00<00:00, 105.10it/s, loss=-0.572, v_num=1e+7, val_loss=-.556]\n",
      "Epoch 5: 100%|██████████| 32/32 [00:00<00:00, 105.60it/s, loss=-0.572, v_num=1e+7, val_loss=-.538]\n",
      "Epoch 6:  78%|███████▊  | 25/32 [00:00<00:00, 88.67it/s, loss=-0.573, v_num=1e+7, val_loss=-.538] \n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 6:  81%|████████▏ | 26/32 [00:00<00:00, 87.72it/s, loss=-0.573, v_num=1e+7, val_loss=-.538]\n",
      "Epoch 6:  84%|████████▍ | 27/32 [00:00<00:00, 89.16it/s, loss=-0.573, v_num=1e+7, val_loss=-.538]\n",
      "Epoch 6:  88%|████████▊ | 28/32 [00:00<00:00, 90.61it/s, loss=-0.573, v_num=1e+7, val_loss=-.538]\n",
      "Epoch 6:  91%|█████████ | 29/32 [00:00<00:00, 91.93it/s, loss=-0.573, v_num=1e+7, val_loss=-.538]\n",
      "Epoch 6:  94%|█████████▍| 30/32 [00:00<00:00, 93.36it/s, loss=-0.573, v_num=1e+7, val_loss=-.538]\n",
      "Epoch 6:  97%|█████████▋| 31/32 [00:00<00:00, 94.96it/s, loss=-0.573, v_num=1e+7, val_loss=-.538]\n",
      "Epoch 6: 100%|██████████| 32/32 [00:00<00:00, 95.97it/s, loss=-0.573, v_num=1e+7, val_loss=-.553]\n",
      "Epoch 7:  78%|███████▊  | 25/32 [00:00<00:00, 100.38it/s, loss=-0.543, v_num=1e+7, val_loss=-.553]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 7:  81%|████████▏ | 26/32 [00:00<00:00, 98.56it/s, loss=-0.543, v_num=1e+7, val_loss=-.553] \n",
      "Epoch 7:  84%|████████▍ | 27/32 [00:00<00:00, 100.68it/s, loss=-0.543, v_num=1e+7, val_loss=-.553]\n",
      "Epoch 7:  88%|████████▊ | 28/32 [00:00<00:00, 102.74it/s, loss=-0.543, v_num=1e+7, val_loss=-.553]\n",
      "Epoch 7:  91%|█████████ | 29/32 [00:00<00:00, 104.82it/s, loss=-0.543, v_num=1e+7, val_loss=-.553]\n",
      "Epoch 7:  94%|█████████▍| 30/32 [00:00<00:00, 106.80it/s, loss=-0.543, v_num=1e+7, val_loss=-.553]\n",
      "Epoch 7:  97%|█████████▋| 31/32 [00:00<00:00, 108.74it/s, loss=-0.543, v_num=1e+7, val_loss=-.553]\n",
      "Epoch 7: 100%|██████████| 32/32 [00:00<00:00, 109.97it/s, loss=-0.543, v_num=1e+7, val_loss=-.515]\n",
      "Epoch 8:  78%|███████▊  | 25/32 [00:00<00:00, 99.32it/s, loss=-0.54, v_num=1e+7, val_loss=-.515]  \n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 8:  81%|████████▏ | 26/32 [00:00<00:00, 98.40it/s, loss=-0.54, v_num=1e+7, val_loss=-.515]\n",
      "Epoch 8:  84%|████████▍ | 27/32 [00:00<00:00, 100.49it/s, loss=-0.54, v_num=1e+7, val_loss=-.515]\n",
      "Epoch 8:  88%|████████▊ | 28/32 [00:00<00:00, 102.67it/s, loss=-0.54, v_num=1e+7, val_loss=-.515]\n",
      "Epoch 8:  91%|█████████ | 29/32 [00:00<00:00, 104.75it/s, loss=-0.54, v_num=1e+7, val_loss=-.515]\n",
      "Epoch 8:  94%|█████████▍| 30/32 [00:00<00:00, 106.67it/s, loss=-0.54, v_num=1e+7, val_loss=-.515]\n",
      "Epoch 8:  97%|█████████▋| 31/32 [00:00<00:00, 108.55it/s, loss=-0.54, v_num=1e+7, val_loss=-.515]\n",
      "Epoch 8: 100%|██████████| 32/32 [00:00<00:00, 109.64it/s, loss=-0.54, v_num=1e+7, val_loss=-.506]\n",
      "Epoch 9:  78%|███████▊  | 25/32 [00:00<00:00, 94.28it/s, loss=-0.533, v_num=1e+7, val_loss=-.506]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 9:  81%|████████▏ | 26/32 [00:00<00:00, 92.31it/s, loss=-0.533, v_num=1e+7, val_loss=-.506]\n",
      "Epoch 9:  84%|████████▍ | 27/32 [00:00<00:00, 94.13it/s, loss=-0.533, v_num=1e+7, val_loss=-.506]\n",
      "Epoch 9:  88%|████████▊ | 28/32 [00:00<00:00, 96.24it/s, loss=-0.533, v_num=1e+7, val_loss=-.506]\n",
      "Epoch 9:  91%|█████████ | 29/32 [00:00<00:00, 98.21it/s, loss=-0.533, v_num=1e+7, val_loss=-.506]\n",
      "Epoch 9:  94%|█████████▍| 30/32 [00:00<00:00, 100.15it/s, loss=-0.533, v_num=1e+7, val_loss=-.506]\n",
      "Epoch 9:  97%|█████████▋| 31/32 [00:00<00:00, 102.03it/s, loss=-0.533, v_num=1e+7, val_loss=-.506]\n",
      "Epoch 9: 100%|██████████| 32/32 [00:00<00:00, 103.22it/s, loss=-0.533, v_num=1e+7, val_loss=-.548]\n",
      "Epoch 10:  78%|███████▊  | 25/32 [00:00<00:00, 96.68it/s, loss=-0.57, v_num=1e+7, val_loss=-.548] \n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 10:  81%|████████▏ | 26/32 [00:00<00:00, 95.97it/s, loss=-0.57, v_num=1e+7, val_loss=-.548]\n",
      "Epoch 10:  84%|████████▍ | 27/32 [00:00<00:00, 98.05it/s, loss=-0.57, v_num=1e+7, val_loss=-.548]\n",
      "Epoch 10:  88%|████████▊ | 28/32 [00:00<00:00, 100.20it/s, loss=-0.57, v_num=1e+7, val_loss=-.548]\n",
      "Epoch 10:  91%|█████████ | 29/32 [00:00<00:00, 102.36it/s, loss=-0.57, v_num=1e+7, val_loss=-.548]\n",
      "Epoch 10:  94%|█████████▍| 30/32 [00:00<00:00, 104.44it/s, loss=-0.57, v_num=1e+7, val_loss=-.548]\n",
      "Epoch 10:  97%|█████████▋| 31/32 [00:00<00:00, 106.42it/s, loss=-0.57, v_num=1e+7, val_loss=-.548]\n",
      "Epoch 10: 100%|██████████| 32/32 [00:00<00:00, 107.66it/s, loss=-0.57, v_num=1e+7, val_loss=-.526]\n",
      "Epoch 11:  78%|███████▊  | 25/32 [00:00<00:00, 104.40it/s, loss=-0.537, v_num=1e+7, val_loss=-.526]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 11:  81%|████████▏ | 26/32 [00:00<00:00, 102.90it/s, loss=-0.537, v_num=1e+7, val_loss=-.526]\n",
      "Epoch 11:  84%|████████▍ | 27/32 [00:00<00:00, 105.10it/s, loss=-0.537, v_num=1e+7, val_loss=-.526]\n",
      "Epoch 11:  88%|████████▊ | 28/32 [00:00<00:00, 107.22it/s, loss=-0.537, v_num=1e+7, val_loss=-.526]\n",
      "Epoch 11:  91%|█████████ | 29/32 [00:00<00:00, 109.35it/s, loss=-0.537, v_num=1e+7, val_loss=-.526]\n",
      "Epoch 11:  94%|█████████▍| 30/32 [00:00<00:00, 111.41it/s, loss=-0.537, v_num=1e+7, val_loss=-.526]\n",
      "Epoch 11:  97%|█████████▋| 31/32 [00:00<00:00, 113.48it/s, loss=-0.537, v_num=1e+7, val_loss=-.526]\n",
      "Epoch 11: 100%|██████████| 32/32 [00:00<00:00, 114.77it/s, loss=-0.537, v_num=1e+7, val_loss=-.565]\n",
      "Epoch 12:  78%|███████▊  | 25/32 [00:00<00:00, 93.21it/s, loss=-0.498, v_num=1e+7, val_loss=-.565] \n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 12:  81%|████████▏ | 26/32 [00:00<00:00, 92.76it/s, loss=-0.498, v_num=1e+7, val_loss=-.565]\n",
      "Epoch 12:  84%|████████▍ | 27/32 [00:00<00:00, 94.91it/s, loss=-0.498, v_num=1e+7, val_loss=-.565]\n",
      "Epoch 12:  88%|████████▊ | 28/32 [00:00<00:00, 97.04it/s, loss=-0.498, v_num=1e+7, val_loss=-.565]\n",
      "Epoch 12:  91%|█████████ | 29/32 [00:00<00:00, 99.17it/s, loss=-0.498, v_num=1e+7, val_loss=-.565]\n",
      "Epoch 12:  94%|█████████▍| 30/32 [00:00<00:00, 101.15it/s, loss=-0.498, v_num=1e+7, val_loss=-.565]\n",
      "Epoch 12:  97%|█████████▋| 31/32 [00:00<00:00, 103.11it/s, loss=-0.498, v_num=1e+7, val_loss=-.565]\n",
      "Epoch 12: 100%|██████████| 32/32 [00:00<00:00, 104.51it/s, loss=-0.498, v_num=1e+7, val_loss=-.562]\n",
      "Epoch 13:  78%|███████▊  | 25/32 [00:00<00:00, 92.58it/s, loss=-0.589, v_num=1e+7, val_loss=-.562] \n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 13:  81%|████████▏ | 26/32 [00:00<00:00, 91.65it/s, loss=-0.589, v_num=1e+7, val_loss=-.562]\n",
      "Epoch 13:  84%|████████▍ | 27/32 [00:00<00:00, 93.74it/s, loss=-0.589, v_num=1e+7, val_loss=-.562]\n",
      "Epoch 13:  88%|████████▊ | 28/32 [00:00<00:00, 95.85it/s, loss=-0.589, v_num=1e+7, val_loss=-.562]\n",
      "Epoch 13:  91%|█████████ | 29/32 [00:00<00:00, 97.92it/s, loss=-0.589, v_num=1e+7, val_loss=-.562]\n",
      "Epoch 13:  94%|█████████▍| 30/32 [00:00<00:00, 99.97it/s, loss=-0.589, v_num=1e+7, val_loss=-.562]\n",
      "Epoch 13:  97%|█████████▋| 31/32 [00:00<00:00, 101.96it/s, loss=-0.589, v_num=1e+7, val_loss=-.562]\n",
      "Epoch 13: 100%|██████████| 32/32 [00:00<00:00, 103.33it/s, loss=-0.589, v_num=1e+7, val_loss=-.563]\n",
      "Epoch 14:  78%|███████▊  | 25/32 [00:00<00:00, 100.72it/s, loss=-0.532, v_num=1e+7, val_loss=-.563]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 14:  81%|████████▏ | 26/32 [00:00<00:00, 99.79it/s, loss=-0.532, v_num=1e+7, val_loss=-.563] \n",
      "Epoch 14:  84%|████████▍ | 27/32 [00:00<00:00, 101.89it/s, loss=-0.532, v_num=1e+7, val_loss=-.563]\n",
      "Epoch 14:  88%|████████▊ | 28/32 [00:00<00:00, 104.05it/s, loss=-0.532, v_num=1e+7, val_loss=-.563]\n",
      "Epoch 14:  91%|█████████ | 29/32 [00:00<00:00, 106.20it/s, loss=-0.532, v_num=1e+7, val_loss=-.563]\n",
      "Epoch 14:  94%|█████████▍| 30/32 [00:00<00:00, 108.23it/s, loss=-0.532, v_num=1e+7, val_loss=-.563]\n",
      "Epoch 14:  97%|█████████▋| 31/32 [00:00<00:00, 110.26it/s, loss=-0.532, v_num=1e+7, val_loss=-.563]\n",
      "Epoch 14: 100%|██████████| 32/32 [00:00<00:00, 111.54it/s, loss=-0.532, v_num=1e+7, val_loss=-.554]\n",
      "Epoch 15:  78%|███████▊  | 25/32 [00:00<00:00, 90.13it/s, loss=-0.644, v_num=1e+7, val_loss=-.554] \n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 15:  81%|████████▏ | 26/32 [00:00<00:00, 88.37it/s, loss=-0.644, v_num=1e+7, val_loss=-.554]\n",
      "Epoch 15:  84%|████████▍ | 27/32 [00:00<00:00, 90.29it/s, loss=-0.644, v_num=1e+7, val_loss=-.554]\n",
      "Epoch 15:  88%|████████▊ | 28/32 [00:00<00:00, 92.16it/s, loss=-0.644, v_num=1e+7, val_loss=-.554]\n",
      "Epoch 15:  91%|█████████ | 29/32 [00:00<00:00, 94.11it/s, loss=-0.644, v_num=1e+7, val_loss=-.554]\n",
      "Epoch 15:  94%|█████████▍| 30/32 [00:00<00:00, 96.00it/s, loss=-0.644, v_num=1e+7, val_loss=-.554]\n",
      "Epoch 15:  97%|█████████▋| 31/32 [00:00<00:00, 97.90it/s, loss=-0.644, v_num=1e+7, val_loss=-.554]\n",
      "Epoch 15: 100%|██████████| 32/32 [00:00<00:00, 99.23it/s, loss=-0.644, v_num=1e+7, val_loss=-.527]\n",
      "Epoch 16:  78%|███████▊  | 25/32 [00:00<00:00, 95.36it/s, loss=-0.571, v_num=1e+7, val_loss=-.527]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 16:  81%|████████▏ | 26/32 [00:00<00:00, 94.53it/s, loss=-0.571, v_num=1e+7, val_loss=-.527]\n",
      "Epoch 16:  84%|████████▍ | 27/32 [00:00<00:00, 96.60it/s, loss=-0.571, v_num=1e+7, val_loss=-.527]\n",
      "Epoch 16:  88%|████████▊ | 28/32 [00:00<00:00, 98.74it/s, loss=-0.571, v_num=1e+7, val_loss=-.527]\n",
      "Epoch 16:  91%|█████████ | 29/32 [00:00<00:00, 100.84it/s, loss=-0.571, v_num=1e+7, val_loss=-.527]\n",
      "Epoch 16:  94%|█████████▍| 30/32 [00:00<00:00, 102.89it/s, loss=-0.571, v_num=1e+7, val_loss=-.527]\n",
      "Epoch 16:  97%|█████████▋| 31/32 [00:00<00:00, 104.91it/s, loss=-0.571, v_num=1e+7, val_loss=-.527]\n",
      "Epoch 16: 100%|██████████| 32/32 [00:00<00:00, 106.27it/s, loss=-0.571, v_num=1e+7, val_loss=-.520]\n",
      "Epoch 17:  78%|███████▊  | 25/32 [00:00<00:00, 100.91it/s, loss=-0.56, v_num=1e+7, val_loss=-.520] \n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 17:  81%|████████▏ | 26/32 [00:00<00:00, 99.99it/s, loss=-0.56, v_num=1e+7, val_loss=-.520] \n",
      "Epoch 17:  84%|████████▍ | 27/32 [00:00<00:00, 102.24it/s, loss=-0.56, v_num=1e+7, val_loss=-.520]\n",
      "Epoch 17:  88%|████████▊ | 28/32 [00:00<00:00, 104.42it/s, loss=-0.56, v_num=1e+7, val_loss=-.520]\n",
      "Epoch 17:  91%|█████████ | 29/32 [00:00<00:00, 106.57it/s, loss=-0.56, v_num=1e+7, val_loss=-.520]\n",
      "Epoch 17:  94%|█████████▍| 30/32 [00:00<00:00, 108.71it/s, loss=-0.56, v_num=1e+7, val_loss=-.520]\n",
      "Epoch 17:  97%|█████████▋| 31/32 [00:00<00:00, 110.74it/s, loss=-0.56, v_num=1e+7, val_loss=-.520]\n",
      "Epoch 17: 100%|██████████| 32/32 [00:00<00:00, 112.04it/s, loss=-0.56, v_num=1e+7, val_loss=-.527]\n",
      "Epoch 18:  78%|███████▊  | 25/32 [00:00<00:00, 90.09it/s, loss=-0.575, v_num=1e+7, val_loss=-.527] \n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 18:  81%|████████▏ | 26/32 [00:00<00:00, 89.03it/s, loss=-0.575, v_num=1e+7, val_loss=-.527]\n",
      "Epoch 18:  84%|████████▍ | 27/32 [00:00<00:00, 91.06it/s, loss=-0.575, v_num=1e+7, val_loss=-.527]\n",
      "Epoch 18:  88%|████████▊ | 28/32 [00:00<00:00, 93.02it/s, loss=-0.575, v_num=1e+7, val_loss=-.527]\n",
      "Epoch 18:  91%|█████████ | 29/32 [00:00<00:00, 95.01it/s, loss=-0.575, v_num=1e+7, val_loss=-.527]\n",
      "Epoch 18:  94%|█████████▍| 30/32 [00:00<00:00, 96.98it/s, loss=-0.575, v_num=1e+7, val_loss=-.527]\n",
      "Epoch 18:  97%|█████████▋| 31/32 [00:00<00:00, 98.90it/s, loss=-0.575, v_num=1e+7, val_loss=-.527]\n",
      "Epoch 18: 100%|██████████| 32/32 [00:00<00:00, 100.24it/s, loss=-0.575, v_num=1e+7, val_loss=-.546]\n",
      "Epoch 19:  78%|███████▊  | 25/32 [00:00<00:00, 94.04it/s, loss=-0.599, v_num=1e+7, val_loss=-.546] \n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 19:  81%|████████▏ | 26/32 [00:00<00:00, 92.12it/s, loss=-0.599, v_num=1e+7, val_loss=-.546]\n",
      "Epoch 19:  84%|████████▍ | 27/32 [00:00<00:00, 93.93it/s, loss=-0.599, v_num=1e+7, val_loss=-.546]\n",
      "Epoch 19:  88%|████████▊ | 28/32 [00:00<00:00, 96.03it/s, loss=-0.599, v_num=1e+7, val_loss=-.546]\n",
      "Epoch 19:  91%|█████████ | 29/32 [00:00<00:00, 98.00it/s, loss=-0.599, v_num=1e+7, val_loss=-.546]\n",
      "Epoch 19:  94%|█████████▍| 30/32 [00:00<00:00, 99.94it/s, loss=-0.599, v_num=1e+7, val_loss=-.546]\n",
      "Epoch 19:  97%|█████████▋| 31/32 [00:00<00:00, 101.84it/s, loss=-0.599, v_num=1e+7, val_loss=-.546]\n",
      "Epoch 19: 100%|██████████| 32/32 [00:00<00:00, 103.10it/s, loss=-0.599, v_num=1e+7, val_loss=-.554]\n",
      "Epoch 19: 100%|██████████| 32/32 [00:00<00:00, 102.10it/s, loss=-0.599, v_num=1e+7, val_loss=-.554]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=20` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19: 100%|██████████| 32/32 [00:00<00:00, 97.59it/s, loss=-0.599, v_num=1e+7, val_loss=-.554] \n"
     ]
    }
   ],
   "source": [
    "trainer.fit(network, dl_train, dl_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56d59736-7df2-4058-9859-6cd9b2ca44bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ad2574e-04b5-4529-b3d4-047774c54ea5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
